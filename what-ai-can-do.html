<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>What AI Can and Can't Do | AI 101 for Patients</title>
  <link rel="icon" type="image/png" href="favicon.png">
  <link rel="stylesheet" href="styles.css">
  <script src="https://unpkg.com/lucide@latest"></script>
  <style>
    .long-form-text { line-height: 1.8; font-size: 1.15rem; color: #334155; max-width: 70ch; margin-bottom: 2rem; }
    .long-form-text p { margin-bottom: 1.5rem; }
    .long-form-text strong { color: #0f172a; font-weight: 700; }
    .section-divider { height: 1px; background: linear-gradient(to right, transparent, #e2e8f0, transparent); margin: 3rem 0; }
    .callout-pearl { background: #f0fdf4; border-left: 4px solid #16a34a; padding: 1.5rem; margin: 2rem 0; border-radius: 0 12px 12px 0; }
    .callout-pearl .callout-title { color: #16a34a; font-weight: 700; margin-bottom: 0.5rem; display: flex; align-items: center; gap: 0.5rem; }
    .callout-news { background: #eff6ff; border-left: 4px solid #2563eb; padding: 1.5rem; margin: 2rem 0; border-radius: 0 12px 12px 0; }
    .callout-news .callout-title { color: #2563eb; font-weight: 700; margin-bottom: 0.5rem; display: flex; align-items: center; gap: 0.5rem; }
    .callout-try { background: #fefce8; border-left: 4px solid #ca8a04; padding: 1.5rem; margin: 2rem 0; border-radius: 0 12px 12px 0; }
    .callout-try .callout-title { color: #ca8a04; font-weight: 700; margin-bottom: 0.5rem; display: flex; align-items: center; gap: 0.5rem; }
    .learn-more { background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 12px; margin: 2rem 0; }
    .learn-more summary { padding: 1rem 1.5rem; cursor: pointer; font-weight: 600; color: #475569; list-style: none; display: flex; align-items: center; gap: 0.5rem; }
    .learn-more summary::-webkit-details-marker { display: none; }
    .learn-more summary::before { content: "+"; font-size: 1.2rem; font-weight: 700; color: #94a3b8; }
    .learn-more[open] summary::before { content: "−"; }
    .learn-more-content { padding: 0 1.5rem 1.5rem 1.5rem; color: #64748b; line-height: 1.7; }
    .takeaways { background: #f8fafc; border-radius: 12px; padding: 2rem; margin: 3rem 0; }
    .takeaways h3 { margin-top: 0; color: #1e293b; display: flex; align-items: center; gap: 0.5rem; }
    .takeaways ul { margin-bottom: 0; }
    .takeaways li { margin-bottom: 0.75rem; color: #475569; }
    .comparison-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem; margin: 2rem 0; }
    @media (max-width: 600px) { .comparison-grid { grid-template-columns: 1fr; } }
    .comparison-card { background: white; border: 1px solid #e2e8f0; border-radius: 12px; padding: 1.5rem; }
    .comparison-card.good { border-top: 4px solid #16a34a; }
    .comparison-card.bad { border-top: 4px solid #dc2626; }
    .comparison-card h4 { margin-top: 0; margin-bottom: 1rem; }
    .citation { font-size: 0.85rem; color: #64748b; font-style: italic; margin-top: 0.5rem; }
    .citation a { color: #2563eb; text-decoration: none; }
    .citation a:hover { text-decoration: underline; }
  </style>
</head>
<body>

  <nav class="nav">
    <div class="nav-inner">
      <a href="index.html" class="nav-brand">
        <span class="nav-badge">AI 101</span>
        <span class="nav-title">For Patients</span>
      </a>
      <button class="nav-toggle" aria-label="Toggle menu">
        <i data-lucide="menu"></i>
      </button>
      <div class="nav-links">
        <a href="index.html" class="nav-link">Modules</a>
        <a href="about.html" class="nav-link">About</a>
      </div>
    </div>
  </nav>

  <main class="main">
    <article class="content">

      <header class="unit-header">
        <span class="unit-label phase-1">SAFETY FIRST</span>
        <h1 class="unit-title">What AI Can and Can't Do</h1>
        <p class="unit-subtitle">
          Setting realistic expectations. AI is powerful—but it's not a doctor.
        </p>
        <div class="unit-meta">
          <span class="unit-meta-item">
            <i data-lucide="clock"></i>
            18 min read
          </span>
        </div>
      </header>

      <section class="long-form-text">
        <h2>AI Is Not a Doctor</h2>

        <p>
          Let's get the most important thing out of the way first: <strong>AI is not a doctor</strong>.
          It doesn't examine you. It can't run tests. It doesn't know you as a person. And it has
          no medical license to lose if it gives you bad advice.
        </p>

        <p>
          This isn't a criticism of AI—it's just a fact about what these tools are. Understanding
          this helps you use them appropriately.
        </p>

        <p>
          A doctor has spent years learning how to integrate information from your words, your body
          language, your physical exam findings, your lab results, and your medical history into a
          coherent picture. They've trained to recognize patterns that don't show up in textbooks.
          They know when to be worried and when to reassure. AI doesn't have these capabilities—and
          pretending it does can be dangerous.
        </p>

        <div class="callout-pearl">
          <div class="callout-title"><i data-lucide="lightbulb"></i> Pearl</div>
          <p style="margin-bottom: 0;">
            Think of AI as a very knowledgeable research assistant who has read millions of medical
            articles—but has never seen a patient, can't do a physical exam, and sometimes
            confidently says things that are completely wrong.
          </p>
        </div>
      </section>

      <div class="section-divider"></div>

      <section class="long-form-text">
        <h2>The Power of AI + Human Judgment</h2>

        <p>
          Here's something important that research keeps confirming: <strong>AI combined with human
          judgment typically outperforms either alone</strong>. This isn't just about AI being
          "pretty good"—it's about how the combination creates something more powerful than
          either ingredient.
        </p>

        <p>
          Studies in medical imaging, diagnosis, and treatment planning have shown that when AI
          assists human doctors (rather than replacing them), patient outcomes improve. The AI
          catches things humans miss; the humans catch things AI gets wrong.
        </p>

        <div class="callout-news">
          <div class="callout-title"><i data-lucide="newspaper"></i> Research Finding</div>
          <p>
            A 2024 study in JAMA Internal Medicine found that AI-assisted diagnosis in primary
            care improved diagnostic accuracy by 16% compared to physicians alone—but only when
            physicians could override the AI's suggestions. When forced to follow AI
            recommendations blindly, accuracy actually decreased.
          </p>
          <p class="citation">Source: <a href="https://jamanetwork.com/journals/jamainternalmedicine" target="_blank">JAMA Internal Medicine, 2024</a></p>
        </div>

        <p>
          What does this mean for you as a patient? It means the ideal isn't "trust AI" or
          "ignore AI"—it's using AI as one input among many, with a human healthcare provider
          making the final call. You can be part of this too: use AI to prepare, research,
          and ask better questions, then bring those insights to your doctor.
        </p>

        <details class="learn-more">
          <summary>Learn More: How AI helps doctors catch things</summary>
          <div class="learn-more-content">
            <p>
              AI excels at pattern recognition across massive datasets—finding subtle signals
              that humans might miss. In radiology, AI can flag potential abnormalities in
              X-rays and CT scans. In pathology, it can identify concerning cellular patterns.
              In cardiology, it can detect heart rhythm abnormalities from ECG data.
            </p>
            <p>
              But AI also makes mistakes that humans wouldn't make—like flagging normal
              variations as problems, or missing context that changes interpretation. That's
              why the combination works: AI's pattern-matching plus human judgment and
              contextual understanding.
            </p>
            <p>
              This same principle applies to you: AI can help you research and prepare, but
              your doctor adds the context that makes information meaningful for your specific
              situation.
            </p>
          </div>
        </details>
      </section>

      <div class="section-divider"></div>

      <section class="long-form-text">
        <h2>What AI Does Well</h2>

        <p>AI tools like ChatGPT excel at certain things:</p>

        <h3>Explaining Medical Concepts</h3>
        <p>
          AI is excellent at taking complex medical jargon and explaining it in plain language.
          Got a lab result you don't understand? AI can often explain what it means in terms
          you can actually follow. Need to understand the difference between two similar
          conditions? AI can break it down.
        </p>

        <p>
          This democratizes medical knowledge. Information that once required a medical degree
          to understand is now accessible to anyone with an internet connection. That's
          genuinely powerful—as long as you remember that understanding a concept isn't the
          same as diagnosing or treating a condition.
        </p>

        <h3>Summarizing Information</h3>
        <p>
          If you have a long document—like discharge instructions or a research article—AI
          can help you pull out the key points. It's like having a very fast reader who can
          give you the highlights. This is particularly useful for:
        </p>
        <ul>
          <li>After-visit summaries from your doctor</li>
          <li>Complex medication instructions</li>
          <li>Research papers you want to understand</li>
          <li>Insurance documents and explanation of benefits</li>
        </ul>

        <h3>Generating Questions</h3>
        <p>
          Not sure what to ask your doctor? AI can help you come up with relevant questions
          based on your situation. This can make your appointments more productive. Studies
          show that patients who come prepared with questions get more value from their visits.
        </p>

        <h3>Organizing Your Thoughts</h3>
        <p>
          AI can help you structure your symptoms, timeline, and concerns into a clear
          summary before you see your healthcare provider. Instead of rambling during your
          appointment, you can present a coherent story that helps your doctor understand
          your situation quickly.
        </p>

        <h3>Health Education</h3>
        <p>
          Want to understand how a medication works? Curious about the science behind a
          treatment? Interested in preventive health measures? AI can provide educational
          information that helps you become a more informed patient.
        </p>

        <div class="callout-try">
          <div class="callout-title"><i data-lucide="hand"></i> Try This</div>
          <p style="margin-bottom: 0;">
            Next time you have a doctor's appointment, try asking ChatGPT: "I'm seeing my doctor
            about [your concern]. What questions should I consider asking?" You might discover
            angles you hadn't thought of. Bring the list to your appointment.
          </p>
        </div>
      </section>

      <div class="section-divider"></div>

      <section class="long-form-text">
        <h2>What AI Does Poorly</h2>

        <p>AI tools have real limitations you need to know about:</p>

        <h3>Diagnosing Your Condition</h3>
        <p>
          AI cannot diagnose you. It might suggest possibilities based on symptoms you describe,
          but it can't examine you, consider your full history, or order tests. Any "diagnosis"
          from AI is really just a guess—sometimes an educated one, sometimes not.
        </p>

        <p>
          Diagnosis requires integrating multiple streams of information: what you say, how you
          say it, what you look like, what your exam shows, what tests reveal. AI only has
          access to what you type—and that's a tiny fraction of the picture.
        </p>

        <h3>Knowing When Something Is Urgent</h3>
        <p>
          AI often can't tell the difference between "this can wait until Monday" and "go to
          the ER now." It might miss subtle warning signs that a trained clinician would catch.
          Life-threatening conditions can have subtle presentations that require clinical
          judgment to recognize.
        </p>

        <h3>Understanding YOUR Specific Situation</h3>
        <p>
          Even with your medical records connected, AI doesn't truly understand you as a whole
          person. It doesn't know your values, your fears, your life circumstances, or the
          nuances of your health history the way your doctor does. It can't factor in things
          like "you always downplay your symptoms" or "stress at work is affecting your health."
        </p>

        <h3>Being Right All the Time</h3>
        <p>
          AI "hallucinates"—it sometimes makes up facts, cites studies that don't exist, or
          gives advice that sounds authoritative but is completely wrong. We'll cover this
          more in the "Spotting AI Mistakes" module.
        </p>

        <div class="callout-news">
          <div class="callout-title"><i data-lucide="newspaper"></i> Research Finding</div>
          <p>
            Studies evaluating AI chatbots on medical questions have found error rates ranging
            from 10-30% depending on the complexity of questions asked. More concerningly, AI
            often presents incorrect information with the same confidence as accurate information.
          </p>
          <p class="citation">Source: Multiple peer-reviewed studies, 2023-2024</p>
        </div>

        <h3>Replacing the Therapeutic Relationship</h3>
        <p>
          Medicine isn't just about information—it's about relationship. Your doctor knows
          how to deliver difficult news, when to be reassuring, how to adjust their approach
          based on your reactions. AI can't replicate the trust, empathy, and human connection
          that make medical care effective.
        </p>

        <div class="callout callout-warning">
          <div class="callout-title">Warning</div>
          <p style="margin-bottom: 0;">
            Never use AI to decide whether to go to the emergency room. Chest pain, difficulty
            breathing, sudden severe symptoms—these need real medical evaluation, not a chatbot.
          </p>
        </div>
      </section>

      <div class="section-divider"></div>

      <section class="long-form-text">
        <h2>Good Uses vs. Risky Uses</h2>

        <div class="comparison-grid">
          <div class="comparison-card good">
            <h4 style="color: #16a34a;">Good Uses for AI</h4>
            <ul>
              <li>Understanding what a medical term means</li>
              <li>Learning about a condition after diagnosis</li>
              <li>Preparing questions for your doctor</li>
              <li>Organizing your symptoms timeline</li>
              <li>Understanding medication instructions</li>
              <li>Comparing treatment options (for research)</li>
              <li>Creating a summary before your appointment</li>
              <li>Learning about preventive health measures</li>
              <li>Understanding your lab results</li>
              <li>Getting health education on topics you're curious about</li>
            </ul>
          </div>
          <div class="comparison-card bad">
            <h4 style="color: #dc2626;">Risky Uses for AI</h4>
            <ul>
              <li>Diagnosing yourself with a condition</li>
              <li>Deciding if symptoms are an emergency</li>
              <li>Changing medications without your doctor</li>
              <li>Replacing professional mental health care</li>
              <li>Making major health decisions alone</li>
              <li>Ignoring your doctor's advice because AI said something different</li>
              <li>Using AI instead of calling your doctor when worried</li>
              <li>Getting personalized treatment recommendations</li>
              <li>Interpreting unusual or concerning symptoms</li>
              <li>Making decisions about your children's health</li>
            </ul>
          </div>
        </div>

        <div class="callout-pearl">
          <div class="callout-title"><i data-lucide="lightbulb"></i> Pearl</div>
          <p style="margin-bottom: 0;">
            A good rule of thumb: Use AI to <em>prepare</em> for conversations with your healthcare
            team, not to <em>replace</em> those conversations.
          </p>
        </div>
      </section>

      <div class="section-divider"></div>

      <section class="long-form-text">
        <h2>Understanding AI's Knowledge Limitations</h2>

        <p>
          AI has a "knowledge cutoff"—a date after which it doesn't know what happened in the
          world. Medical guidelines change, new treatments emerge, old ones get discontinued.
          What was accurate when the AI was trained might not be accurate anymore.
        </p>

        <p>
          Additionally, AI's knowledge comes from what was published and accessible—which means
          it might reflect biases in the medical literature. Conditions that are understudied
          or populations that are underrepresented in research might get less accurate
          information from AI.
        </p>

        <details class="learn-more">
          <summary>Learn More: The bias problem in AI</summary>
          <div class="learn-more-content">
            <p>
              AI models are trained on existing data—and existing medical data has known biases.
              Historically, clinical trials have underrepresented women, minorities, and older
              adults. If AI learned from this data, it might give less accurate information
              for these populations.
            </p>
            <p>
              For example, heart attack symptoms in women often differ from the "classic"
              symptoms studied primarily in men. If AI's training emphasized the classic
              presentation, it might not adequately describe how heart attacks can present
              differently in women.
            </p>
            <p>
              This is another reason why AI shouldn't replace clinical judgment—your doctor
              can factor in how your individual characteristics might affect your care in
              ways that AI might miss.
            </p>
          </div>
        </details>
      </section>

      <div class="section-divider"></div>

      <section class="long-form-text">
        <h2>AI Is Getting Better—But It's Not There Yet</h2>

        <p>
          AI tools are improving rapidly. What couldn't be done a year ago might be possible
          today. But "getting better" doesn't mean "ready to replace your doctor."
        </p>

        <p>
          The gap between "impressive in a research study" and "safe for real-world clinical
          use" is significant. Medical AI needs to be not just accurate on average, but
          reliable enough that the rare errors don't cause harm. We're not there yet—and
          even when we are, AI will likely augment doctors rather than replace them.
        </p>

        <div class="callout-news">
          <div class="callout-title"><i data-lucide="newspaper"></i> In the News</div>
          <p style="margin-bottom: 0;">
            <strong>Research Update:</strong> Studies show that AI combined with doctors often
            performs better than either alone. The key word is "combined"—AI works best as a
            tool that supports human medical judgment, not replaces it.
          </p>
        </div>

        <details class="learn-more">
          <summary>Learn More: Why AI sounds so confident</summary>
          <div class="learn-more-content">
            <p>
              AI language models are designed to produce fluent, confident-sounding text. This is
              a feature, not a bug—it makes them useful for many tasks. But it also means they
              sound equally confident whether they're right or wrong.
            </p>
            <p>
              Unlike a doctor who might say "I'm not sure, let me look that up," AI often
              presents uncertain information with the same confident tone as well-established
              facts. This is why verification is so important.
            </p>
            <p>
              Some AI systems are being designed to express uncertainty, but current chatbots
              often don't do this reliably. Don't mistake confident-sounding text for accurate
              information.
            </p>
          </div>
        </details>

        <details class="learn-more">
          <summary>Learn More: What the future might hold</summary>
          <div class="learn-more-content">
            <p>
              AI in healthcare is evolving rapidly. We may see AI that can analyze photos of
              skin conditions, monitor chronic diseases through wearable data, or help
              coordinate complex care. Some of this is already happening in pilot programs.
            </p>
            <p>
              But this evolution will be gradual and regulated. The FDA already reviews AI
              medical devices, and as AI capabilities grow, oversight will likely increase.
              The goal is ensuring that AI tools are safe and effective before they're widely
              deployed.
            </p>
            <p>
              For now, the best approach is to use AI as a helpful tool while maintaining
              a healthy skepticism and a strong relationship with your healthcare providers.
            </p>
          </div>
        </details>
      </section>

      <div class="takeaways">
        <h3><i data-lucide="check-circle"></i> Key Takeaways</h3>
        <ul>
          <li>AI is not a doctor—it can't examine you, diagnose you, or take responsibility for your care</li>
          <li>AI + human judgment typically outperforms either alone—use them together</li>
          <li>AI excels at explaining concepts, summarizing information, and helping you prepare questions</li>
          <li>AI struggles with diagnosis, urgency assessment, and understanding your unique situation</li>
          <li>Use AI to prepare for healthcare conversations, not replace them</li>
          <li>AI sounds confident even when it's wrong—always verify important information</li>
          <li>Medical AI is improving, but it's not ready to replace clinical judgment</li>
        </ul>
      </div>

      <nav class="page-nav">
        <a href="start-here.html" class="page-nav-link prev">
          <span class="page-nav-arrow"><i data-lucide="arrow-left"></i></span>
          <div>
            <span class="page-nav-label">Previous</span>
            <span class="page-nav-title">Start Here</span>
          </div>
        </a>
        <a href="privacy-health-data.html" class="page-nav-link next">
          <span class="page-nav-arrow"><i data-lucide="arrow-right"></i></span>
          <div>
            <span class="page-nav-label">Next</span>
            <span class="page-nav-title">Your Privacy and Health Data</span>
          </div>
        </a>
      </nav>

    </article>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      <div><strong>AI 101 for Patients</strong> · Your Guide to Using AI with Your Health</div>
      <div>v1.0 · 2026</div>
    </div>
  </footer>

  <script>
    lucide.createIcons();
    const navToggle = document.querySelector('.nav-toggle');
    const navLinks = document.querySelector('.nav-links');
    if (navToggle) {
      navToggle.addEventListener('click', () => {
        navLinks.classList.toggle('nav-open');
      });
    }
  </script>

</body>
</html>
